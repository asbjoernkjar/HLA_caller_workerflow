import os
import sys
import pandas as pd
configfile: "config/config.yaml"


##### GETTING SAMPLE LIST ########

sample_df = pd.read_csv(config["sample_file"], sep = "\t", dtype = str)
sample_list = sample_df[ config["sample_col"]].to_list()



#input fuction for fetching bam paths 
def extract_from_sample(df,key_col,val_col) :
    """Function that can extract a datapoint from df - crashes on multiple matches"""
    def input_func(wildcards):

        return  df.loc[df[key_col] == wildcards.sample, val_col].item()
    return input_func

get_bam = extract_from_sample(sample_df,config["sample_col"],config["bam_col"] )


########### RULES #############




#do consensus vote?
vote_out = [] if not config["consensus_vote"] else "results/HLA/concensus_vote.concat.tsv"

rule all: 
    input: 
        #final_out
        "results/HLA/polysolver.formated.concat.tsv",
        "results/HLA/polysolver.full.concat.tsv",
        vote_out


### POLYSOLVER ###
module polysolver_workflow:
    snakefile: "rules/run_polysolver.smk.py"
    config: config

use rule format_polysolver_calls from polysolver_workflow 

use rule POLYSOLVER from polysolver_workflow with:
    input:
        get_bam


### xHLA ###
module xhla_workflow:
    snakefile: "rules/run_xHLA.smk.py"
    config: config

use rule format_xhla_calls from xhla_workflow 

use rule xHLA from xhla_workflow with:
    input:
        get_bam

### Optitype ###
rule gen_fastq:
    conda:
        "envs/samtools.yaml"
    resources:
        walltime = "1:00:00",  
        mem_mb = 8000,
    input:
        get_bam
    output:
        R1 = "temp/fastq/{sample}.R1.fq",#temp("temp/fastq/{sample}.R1.fq"),
        R2 = "temp/fastq/{sample}.R2.fq"#temp("temp/fastq/{sample}.R2.fq"),
    params:
        tmp = "temp/fastq/tmp/{sample}"
    shell:"""
    mkdir -p {params.tmp}
    samtools collate -u -O '{input}' {params.tmp} | \
    samtools fastq -1 '{output.R1}' -2 '{output.R2}' -0 /dev/null -s /dev/null -n
    """
    
module optitype_workflow:
    snakefile: "rules/run_optitype.smk.py"
    config: config

use rule format_optitype_calls from optitype_workflow 

use rule optitype from optitype_workflow with:
    input:
        R1 = "temp/fastq/{sample}.R1.fq",
        R2 = "temp/fastq/{sample}.R2.fq"



module consensus_vote_rule:
    snakefile: "rules/consensus_vote.smk.py"

use rule consensus_vote from consensus_vote_rule 



rule concat_poly:
    input:
        format = expand("results/HLA/polysolver/formated/{sample}.polysolver.formated.tsv", sample = sample_list),
        full = expand("results/HLA/polysolver/full/{sample}.polysolver.full.tsv", sample = sample_list),
    output: 
        format = "results/HLA/polysolver.formated.concat.tsv",
        full   = "results/HLA/polysolver.full.concat.tsv"

    shell:""" 
    awk 'FNR>1 || NR==1' {input.format} > {output.format}
    awk 'FNR>1 || NR==1' {input.full} > {output.full}
    """


rule concat_consensus:
    input:
        expand("results/HLA/consensus_vote/{sample}.consensus_vote.tsv", sample = sample_list)
    output: 
        out = "results/HLA/concensus_vote.concat.tsv",
    shell:""" 
    awk 'FNR>1 || NR==1' {input} > {output.out}
    """




# rule xHLA:
#     #calls xHLA
#     threads: 1
#     resources:
#         walltime="1:00:00",
#         mem_mb = 8092,
#         # walltime="2:00:00",  #run with this if you get OOM fails
#         # mem_mb = 20092,
#     input:
#         "results/bam_files/{sample}.bam",
#         "results/bam_files/{sample}.bam.bai"
#     output:
#         "results/xhla/calls/report-{sample}-hla.json"
#     params:
#         path_results = "results/xhla/calls",
#         path_sample = "results/bam_files/{sample}.bam",
#         path_bams_absolute = config["PATH_BAMS_ABSOLUTE"],
#         sample = "{sample}",
#         path_wd = config["PATH_WD"] + "/tmp"
#     shell: """
#         sleep $[ ( $RANDOM % 60 )  + 1 ]s
#         cd tmp && \
#         singularity run  \
#             -B {params.path_bams_absolute} \
#             -B {params.path_wd}:{params.path_wd} \
#             -W {params.path_wd} \
#             ../xhla.sif \
#             --sample_id {wildcards.sample} \
#             --input_bam_path ../{params.path_sample} \
#                --output_path ../{params.path_results}
#         """



# rule optitype:
#     #First converts BAM file to 2 fq files, then runs optitype
#     #fq files are removed after each call --> to not use extreme amounts of storage during large workflows
#     threads: 1
#     resources:
#         walltime="1:00:00",
#         mem_mb = 8092
#     conda:
#         "envs/samtools.yaml"
#     input:
#         "results/bam_files/{sample}.bam"
#     output:
#         "results/optitype/calls/{sample}_result.tsv"
#     params:
#         path_results = "results/optitype/calls",
#         tmp = "tmp/tmp_opti_{sample}",
#         path_bams = "results/bam_files",
#         sample = "{sample}.bam",
#         sample_name = "{sample}",
#     shell: """
#         sleep $[ ( $RANDOM % 60 )  + 1 ]s
#         mkdir -p {params.tmp}/
#         samtools collate -u {params.path_bams}/{params.sample_name}.bam -o {params.tmp}/{params.sample_name}_sorted.bam {params.tmp}
#         samtools fastq {params.tmp}/{params.sample_name}_sorted.bam -1 {params.tmp}/{params.sample_name}_1.fq -2 {params.tmp}/{params.sample_name}_2.fq -0 /dev/null -s /dev/null -n
#         singularity run  \
#         optitype.sif \
#             -i {params.tmp}/{params.sample_name}_1.fq {params.tmp}/{params.sample_name}_2.fq \
#             -d \
#             -p {params.sample_name} \
#             -o {params.tmp}/ \
#             -v
#         cp {params.tmp}/{params.sample_name}_result.tsv  {params.path_results}/{params.sample_name}_result.tsv
#         rm {params.tmp}/{params.sample_name}_sorted.bam
#         rm {params.tmp}/{params.sample_name}_1.fq
#         rm {params.tmp}/{params.sample_name}_2.fq
#         """

#     #single end mode:
#     # samtools fastq {params.path_bams}{params.sample_name}.bam > {params.tmp}/{params.sample_name}.fq
#     #-i {params.tmp}/{params.sample_name}.fq \

# rule merge_polysolver_calls:
#     #takes the individual call files and stores them in dataframe
#     #note original and formated HLA types are both saved
#     input:
#         file_list = expand("results/polysolver/calls"+"/winners.hla.{sample_name}.txt", \
#                 sample_name = sample_list)
#     output:
#         full ="results/polysolver/calls_full.tsv",
#         formated="results/polysolver/calls_formated.tsv"
#     params:
#         sample_list = sample_list
#     script:
#         "scripts/merge_polysolver_calls.py"

# rule merge_xhla_calls:
#     #takes the individual call files and stores them in dataframe
#     #note original and formated HLA types are both saved
#     input: 
#         file_list = expand("results/xhla/calls/report-{sample_name}-hla.json", \
#                 sample_name = sample_list)
#     output:
#         formated = "results/xhla/calls_formated.tsv",
#         full = "results/xhla/calls_full.tsv"
#     params:
#         sample_list = sample_list
#     script:
#         "scripts/merge_xhla_calls.py"

# rule merge_optitype_calls:
#     input: 
#         file_list = expand("results/optitype/calls/{sample_name}_result.tsv", \
#                 sample_name = sample_list)
#     output:
#         formated = "results/optitype/calls_formated.tsv",
#         full = "results/optitype/calls_full.tsv"
#     params:
#         sample_list = sample_list
#     script:
#         "scripts/merge_optitype_calls.py"


# #Creating input for the merge function
# #we cannot merge something thas doesn't exist
# merge_all_input = []
# if config["USE_POLYSOLVER"]:
#     merge_all_input.append("results/polysolver/calls_formated.tsv")
# if config["USE_XHLA"]:
#     merge_all_input.append("results/xhla/calls_formated.tsv")
# if config["USE_OPTITYPE"]:
#     merge_all_input.append("results/optitype/calls_formated.tsv")

# rule merge_all:
#     #merges all data frames 
#     resources:
#         walltime="0:30:00"
#     input:
#         merge_all_input
#     output:
#         "results/calls.tsv"
#     script:
#         "scripts/merge_all.py"


# #if config["USE_POLYSOLVER"] and config["USE_XHLA"] and config["USE_OPTITYPE"]:
# rule consensus_call:
#     #Do consensus vote
#     resources:
#         walltime="0:30:00"
#     input:
#         calls = "results/calls.tsv",
#         allowed = "config/MHC_allele_names.txt"
#     output:
#         "results/consensus_calls.tsv"
#     script:
#         "scripts/consensus_vote.py"

